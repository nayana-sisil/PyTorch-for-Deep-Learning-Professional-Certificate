{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a877f9bf-8818-4b9c-ab02-65bda7ea5099",
   "metadata": {},
   "source": [
    "# Building Your First Image Classifier\n",
    "\n",
    "Welcome to this hands-on lab where you'll build, train, and evaluate your first image classifier using PyTorch! You’ve already learned the core concepts behind the deep learning pipeline, and now it’s time to put that knowledge into practice. Your goal now is to create a neural network that can recognize handwritten digits from the **MNIST dataset**.\n",
    "\n",
    "By the end of this notebook, you will have gone through the entire end-to-end process. Specifically, you will:\n",
    "- **Prepare your data:** Load the MNIST dataset, inspect its format, and apply essential transformations.  \n",
    "- **Build your model:** Define a custom neural network using PyTorch’s flexible `nn.Module` class.  \n",
    "- **Train your model:** Implement the full training process with a loss function, optimizer, and training loop.  \n",
    "- **Analyze your results:** Evaluate your model on unseen data and visualize its performance.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcba0c6-c596-4346-850d-c114ca0c6463",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95baeacf-baf2-4ce4-b2ca-86a420e68ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import helper_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281c6490-abc8-431b-8071-551be76e1b13",
   "metadata": {},
   "source": [
    "* The code below selects the best available hardware on your system to speed up model training.\n",
    "    * **CUDA**: Runs on NVIDIA GPUs, which are widely used for deep learning and typically offer the fastest training performance. \n",
    "    * **MPS**: Runs on Apple Silicon GPUs, providing efficient acceleration on modern Mac systems.\n",
    "    * **CPU**: Runs on the Central Processing Unit, the standard processor every computer has. PyTorch will automatically use it if no compatible GPU is detected.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d24835c2-a803-4fb5-bc27-016aa56abafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: CPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"Using device: CUDA\")\n",
    "elif torch.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(f\"Using device: MPS (Apple Silicon GPU)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"Using device: CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ceb0fd-70d4-4deb-80b0-b95e2c62c096",
   "metadata": {},
   "source": [
    "## MNIST Dataset: Preparing your Data\n",
    "\n",
    "The [MNIST dataset](https://docs.pytorch.org/vision/main/generated/torchvision.datasets.MNIST.html) is a classic benchmark for image classification and is often considered the “hello world” of computer vision. It contains 60,000 training images and 10,000 test images. Each image is 28 by 28 pixels, in grayscale, showing a single handwritten digit from 0 to 9.\n",
    "\n",
    "Before a model can learn from this data, you need to convert the images into numbers that a neural network can process. Each pixel becomes a numerical value representing its brightness, and together these numbers form a **tensor**, which is the format PyTorch models use for computation. Neural networks train best when these input values are small and centered around zero because that helps gradients flow more smoothly and makes learning more stable. To achieve this, you will **normalize** the pixel values so they fall within that range.\n",
    "\n",
    "To see exactly what this means, you’ll start by loading the MNIST training data directly from `torchvision`, PyTorch’s library for computer vision tasks. You won’t apply any transformations yet. Instead, you’ll inspect a raw image to see what the data looks like before any changes, and later compare how that same image appears once it’s been prepared for the model.\n",
    "\n",
    "- Define `data_path` that specifies the folder where your dataset will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e66989d8-1920-4953-81c3-b9c3415e62d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to store the dataset files\n",
    "data_path = \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559e66af-6e25-4877-a2bb-4f5b05cb6cfe",
   "metadata": {},
   "source": [
    "* Load the MNIST dataset using `torchvision.datasets.MNIST`.\n",
    "    * `root`: This tells PyTorch where to save the dataset files. In this case, at the location of the `data_path` you just defined.\n",
    "    * `train`: Setting this to `True` ensures you get the training split of the dataset, which contains 60,000 images.\n",
    "    * `download`: This handy parameter tells PyTorch to automatically download the files if they are not already present in your root folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0afdb499-5693-41ae-be98-acf7d2b7e788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 9.91M/9.91M [00:02<00:00, 3.54MB/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 28.9k/28.9k [00:00<00:00, 115kB/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 1.65M/1.65M [00:01<00:00, 1.02MB/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 4.54k/4.54k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset_without_transform = torchvision.datasets.MNIST(root=data_path, train=True, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea73a6f4-33cc-42b2-b091-aea73c3953b3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Now that you've loaded the dataset, you can inspect an individual item from it.\n",
    "\n",
    "* You can retrieve any sample from your `Dataset` object just like a Python list by using its index. Here, you'll access the first item at index `0`.\n",
    "* Notice that each item is a **tuple** containing two parts: the image data and its corresponding numerical label.\n",
    "* After running the code, you should see the following:\n",
    "    * The image is a **PIL Image** object, a common Python format for image data.\n",
    "    * Its dimensions are **(28, 28)**, which matches the MNIST image size.\n",
    "    * The label is an integer representing the digit shown in the image.\n",
    "    \n",
    "> **A Note on Labels**: \n",
    ">\n",
    ">    Datasets in PyTorch return labels as **numerical indices**, not text. For the **MNIST dataset**, this is straightforward: index `0` represents the digit `0`, index `1` represents the digit `1`, and so on.\n",
    ">\n",
    ">    This relationship between label indices and their meanings is less direct in other datasets. For example, if you were working with images of cats and dogs, the labels would still be 0 and 1, not the words “cat” or “dog.” In those cases, you might create a list such as class_names = ['cat', 'dog']` to map the numeric labels back to readable names when displaying results or debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40f2d21-5dec-40c1-9ded-2a589e57886d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
